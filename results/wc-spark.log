2018-11-05 04:19:33 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-05 04:19:33 INFO  SparkContext:54 - Running Spark version 2.3.2
2018-11-05 04:19:33 INFO  SparkContext:54 - Submitted application: JavaWordCount
2018-11-05 04:19:33 INFO  SecurityManager:54 - Changing view acls to: spark,hadoop
2018-11-05 04:19:33 INFO  SecurityManager:54 - Changing modify acls to: spark,hadoop
2018-11-05 04:19:33 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-11-05 04:19:33 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-11-05 04:19:33 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(spark, hadoop); groups with modify permissions: Set()
2018-11-05 04:19:33 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 33093.
2018-11-05 04:19:33 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-11-05 04:19:34 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-11-05 04:19:34 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-05 04:19:34 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-11-05 04:19:34 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-fa330b0d-74a9-4106-a040-77fad069bb13
2018-11-05 04:19:34 INFO  MemoryStore:54 - MemoryStore started with capacity 413.9 MB
2018-11-05 04:19:34 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-11-05 04:19:34 INFO  log:192 - Logging initialized @3042ms
2018-11-05 04:19:34 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-11-05 04:19:34 INFO  Server:419 - Started @3174ms
2018-11-05 04:19:34 INFO  AbstractConnector:278 - Started ServerConnector@51bba83f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-05 04:19:34 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3aacf32a{/jobs,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ce1f601{/jobs/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38875e7d{/jobs/job,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d816dde{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e33c391{/stages,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c451c9c{/stages/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31c269fd{/stages/stage,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3113a37{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@213e3629{/stages/pool,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e9658b5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a7b6f69{/storage,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20312893{/storage/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70eecdc2{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c41709a{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7db0565c{/environment,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54ec8cc9{/environment/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52eacb4b{/executors,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5528a42c{/executors/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a551a63{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a6f5124{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1edb61b1{/static,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52d10fb8{/,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41c07648{/api,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60d84f61{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39c11e6c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-05 04:19:34 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://ip-10-1-1-100.ec2.internal:4040
2018-11-05 04:19:34 INFO  SparkContext:54 - Added JAR file:/opt/spark/examples/jars/spark-examples_2.11-2.3.2.jar at spark://ip-10-1-1-100.ec2.internal:33093/jars/spark-examples_2.11-2.3.2.jar with timestamp 1541391574735
2018-11-05 04:19:34 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://ip-10-1-1-100.ec2.internal:7077...
2018-11-05 04:19:34 INFO  TransportClientFactory:267 - Successfully created connection to ip-10-1-1-100.ec2.internal/10.1.1.100:7077 after 53 ms (0 ms spent in bootstraps)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20181105041935-0002
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/0 on worker-20181105040822-10.1.1.18-39885 (10.1.1.18:39885) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/0 on hostPort 10.1.1.18:39885 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32927.
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/1 on worker-20181105040822-10.1.1.17-33515 (10.1.1.17:33515) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/1 on hostPort 10.1.1.17:33515 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  NettyBlockTransferService:54 - Server created on ip-10-1-1-100.ec2.internal:32927
2018-11-05 04:19:35 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/2 on worker-20181105040822-10.1.1.11-33671 (10.1.1.11:33671) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/2 on hostPort 10.1.1.11:33671 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/3 on worker-20181105040822-10.1.1.13-44111 (10.1.1.13:44111) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/3 on hostPort 10.1.1.13:44111 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/4 on worker-20181105040822-10.1.1.10-42607 (10.1.1.10:42607) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/4 on hostPort 10.1.1.10:42607 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/5 on worker-20181105040822-10.1.1.19-44659 (10.1.1.19:44659) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/5 on hostPort 10.1.1.19:44659 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/6 on worker-20181105040822-10.1.1.16-33629 (10.1.1.16:33629) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/6 on hostPort 10.1.1.16:33629 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/7 on worker-20181105040822-10.1.1.12-35955 (10.1.1.12:35955) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/7 on hostPort 10.1.1.12:35955 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/8 on worker-20181105040822-10.1.1.15-36315 (10.1.1.15:36315) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/8 on hostPort 10.1.1.15:36315 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181105041935-0002/9 on worker-20181105040822-10.1.1.14-36857 (10.1.1.14:36857) with 1 core(s)
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181105041935-0002/9 on hostPort 10.1.1.14:36857 with 1 core(s), 1024.0 MB RAM
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/0 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/1 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/4 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/2 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/3 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/6 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/5 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/8 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/9 is now RUNNING
2018-11-05 04:19:35 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181105041935-0002/7 is now RUNNING
2018-11-05 04:19:35 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, ip-10-1-1-100.ec2.internal, 32927, None)
2018-11-05 04:19:35 INFO  BlockManagerMasterEndpoint:54 - Registering block manager ip-10-1-1-100.ec2.internal:32927 with 413.9 MB RAM, BlockManagerId(driver, ip-10-1-1-100.ec2.internal, 32927, None)
2018-11-05 04:19:35 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, ip-10-1-1-100.ec2.internal, 32927, None)
2018-11-05 04:19:35 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, ip-10-1-1-100.ec2.internal, 32927, None)
2018-11-05 04:19:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2d84cb86{/metrics/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:35 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2018-11-05 04:19:35 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/spark/spark-warehouse').
2018-11-05 04:19:35 INFO  SharedState:54 - Warehouse path is 'file:/opt/spark/spark-warehouse'.
2018-11-05 04:19:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61a91912{/SQL,null,AVAILABLE,@Spark}
2018-11-05 04:19:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1763992e{/SQL/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@47f08b81{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-05 04:19:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b9dfc5a{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-05 04:19:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b022357{/static/sql,null,AVAILABLE,@Spark}
2018-11-05 04:19:36 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.19:49520) with ID 5
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.18:36072) with ID 0
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.10:42826) with ID 4
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.17:37432) with ID 1
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.15:42430) with ID 8
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.16:37190) with ID 6
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.12:50248) with ID 7
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.11:59134) with ID 2
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.14:41782) with ID 9
2018-11-05 04:19:38 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.1.13:42662) with ID 3
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.19:40437 with 413.9 MB RAM, BlockManagerId(5, 10.1.1.19, 40437, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.10:33015 with 413.9 MB RAM, BlockManagerId(4, 10.1.1.10, 33015, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.18:43623 with 413.9 MB RAM, BlockManagerId(0, 10.1.1.18, 43623, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.15:35541 with 413.9 MB RAM, BlockManagerId(8, 10.1.1.15, 35541, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.17:38215 with 413.9 MB RAM, BlockManagerId(1, 10.1.1.17, 38215, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.12:45109 with 413.9 MB RAM, BlockManagerId(7, 10.1.1.12, 45109, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.16:40181 with 413.9 MB RAM, BlockManagerId(6, 10.1.1.16, 40181, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.11:42907 with 413.9 MB RAM, BlockManagerId(2, 10.1.1.11, 42907, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.14:35891 with 413.9 MB RAM, BlockManagerId(9, 10.1.1.14, 35891, None)
2018-11-05 04:19:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.1.1.13:42333 with 413.9 MB RAM, BlockManagerId(3, 10.1.1.13, 42333, None)
2018-11-05 04:19:42 INFO  FileSourceStrategy:54 - Pruning directories with: 
2018-11-05 04:19:42 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2018-11-05 04:19:42 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2018-11-05 04:19:42 INFO  FileSourceScanExec:54 - Pushed Filters: 
2018-11-05 04:19:42 INFO  CodeGenerator:54 - Code generated in 371.584931 ms
2018-11-05 04:19:43 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 277.2 KB, free 413.7 MB)
2018-11-05 04:19:43 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.8 KB, free 413.6 MB)
2018-11-05 04:19:43 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on ip-10-1-1-100.ec2.internal:32927 (size: 23.8 KB, free: 413.9 MB)
2018-11-05 04:19:43 INFO  SparkContext:54 - Created broadcast 0 from javaRDD at JavaWordCount.java:45
2018-11-05 04:19:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-11-05 04:19:43 INFO  SparkContext:54 - Starting job: collect at JavaWordCount.java:53
2018-11-05 04:19:43 INFO  DAGScheduler:54 - Registering RDD 5 (mapToPair at JavaWordCount.java:49)
2018-11-05 04:19:43 INFO  DAGScheduler:54 - Got job 0 (collect at JavaWordCount.java:53) with 1 output partitions
2018-11-05 04:19:43 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (collect at JavaWordCount.java:53)
2018-11-05 04:19:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2018-11-05 04:19:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2018-11-05 04:19:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at JavaWordCount.java:49), which has no missing parents
2018-11-05 04:19:43 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.4 KB, free 413.6 MB)
2018-11-05 04:19:43 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 413.6 MB)
2018-11-05 04:19:43 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on ip-10-1-1-100.ec2.internal:32927 (size: 6.4 KB, free: 413.9 MB)
2018-11-05 04:19:43 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-11-05 04:19:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at JavaWordCount.java:49) (first 15 tasks are for partitions Vector(0))
2018-11-05 04:19:43 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2018-11-05 04:19:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, 10.1.1.11, executor 2, partition 0, ANY, 8304 bytes)
2018-11-05 04:19:44 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.1.1.11:42907 (size: 6.4 KB, free: 413.9 MB)
2018-11-05 04:19:47 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.1.1.11:42907 (size: 23.8 KB, free: 413.9 MB)
2018-11-05 04:19:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 5302 ms on 10.1.1.11 (executor 2) (1/1)
2018-11-05 04:19:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-11-05 04:19:49 INFO  DAGScheduler:54 - ShuffleMapStage 0 (mapToPair at JavaWordCount.java:49) finished in 5.464 s
2018-11-05 04:19:49 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-11-05 04:19:49 INFO  DAGScheduler:54 - running: Set()
2018-11-05 04:19:49 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2018-11-05 04:19:49 INFO  DAGScheduler:54 - failed: Set()
2018-11-05 04:19:49 INFO  DAGScheduler:54 - Submitting ResultStage 1 (ShuffledRDD[6] at reduceByKey at JavaWordCount.java:51), which has no missing parents
2018-11-05 04:19:49 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 413.6 MB)
2018-11-05 04:19:49 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 413.6 MB)
2018-11-05 04:19:49 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on ip-10-1-1-100.ec2.internal:32927 (size: 2.2 KB, free: 413.9 MB)
2018-11-05 04:19:49 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-11-05 04:19:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[6] at reduceByKey at JavaWordCount.java:51) (first 15 tasks are for partitions Vector(0))
2018-11-05 04:19:49 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2018-11-05 04:19:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, 10.1.1.11, executor 2, partition 0, NODE_LOCAL, 7653 bytes)
2018-11-05 04:19:49 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.1.1.11:42907 (size: 2.2 KB, free: 413.9 MB)
2018-11-05 04:19:49 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.1.1.11:59134
2018-11-05 04:19:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 355 ms on 10.1.1.11 (executor 2) (1/1)
2018-11-05 04:19:49 INFO  DAGScheduler:54 - ResultStage 1 (collect at JavaWordCount.java:53) finished in 0.372 s
2018-11-05 04:19:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-11-05 04:19:49 INFO  DAGScheduler:54 - Job 0 finished: collect at JavaWordCount.java:53, took 6.011931 s
Unless: 3
agree: 1
reproduce,: 1
http://jline.sourceforge.net): 1
(or: 3
MERCHANTABILITY,: 1
(https://github.com/typelevel/machinist): 1
AnchorJS: 1
However,: 1
been: 2
http://f2j.sourceforge.net): 1
AntLR: 1
appropriateness: 1
direct,: 1
harmless: 1
9.: 1
(org.scala-lang:scala-compiler:2.11.8: 1
file: 6
file.: 1
are: 8
2.: 1
part: 4
reproduction,: 3
alone: 1
different: 1
grant: 1
"[]": 1
Zstd-jni: 1
FITNESS: 1
be: 5
distribution,: 1
carry: 1
including: 5
combination: 1
license: 8
JLine: 1
Binding: 1
"printed: 1
but: 5
malfunction,: 1
stated: 2
obligations,: 1
5.: 1
Works;: 3
"Legal: 1
make,: 1
associated: 1
Work: 20
http://www.stringtemplate.org): 2
whole,: 2
copyright,: 1
at: 4
object: 1
JPMML-Model: 1
copy: 3
indemnify,: 1
class: 1
behalf: 5
"control": 1
acting: 1
"Object": 1
Accepting: 1
Kryo: 1
give: 1
except: 3
"Work": 1
project: 3
authorized: 2
https://github.com/scopt/scopt): 1
granting: 1
(com.github.fommil.netlib:core:1.1.2: 1
(BSD: 14
names: 1
fields: 1
transfer: 1
(ii): 1
JavaUtils.scala): 1
licenses.: 1
readable: 1
management: 1
marks,: 1
(xmlenc:xmlenc:0.52: 1
litigation: 2
Library: 2
(https://github.com/luben/zstd-jni/blob/master/LICENSE): 1
configuration: 1
(org.slf4j:jul-to-slf4j:1.7.5: 1
(https://github.com/douban/dpark/blob/master/LICENSE): 1
percent: 1
this: 16
limitations: 1
ST4: 1
Contributor,: 1
PARTICULAR: 1
appropriate: 1
d3.min.js: 1
http://github.com/szeiger/junit-interface/): 1
1.: 1
otherwise: 3
Compiler: 2
trademarks,: 1
acceptance: 1
sole: 1
"AS: 2
See: 6
exercise: 1
agreement: 1
(org.spark-project:pyrolite:2.0.1: 1
for: 23
without: 3
reproduce: 1
cause: 2
Subject: 2
control: 2
TERMS: 2
made,: 1
accepting: 2
conditions:: 1
sorttable: 1
"submitted": 1
http://www.scala-lang.org/): 5
pyrolite: 1
was: 1
While: 1
(Two-clause: 1
do: 3
language: 1
entity: 3
License: 9
permissions: 3
WARRANTIES: 2
StringTemplate: 1
Contributions.: 2
How: 1
(https://github.com/cloudpipe/cloudpickle/blob/master/LICENSE): 1
(com.novocode:junit-interface:0.10: 1
reasonable: 1
made: 1
bind: 1
API: 3
apply: 2
http://www.slf4j.org): 4
classes: 1
(https://github.com/facebook/zstd/blob/v1.3.1/LICENSE): 1
spire: 1
one: 1
counterclaim: 1
discussing: 1
in: 25
3: 6
(Interpreter: 1
beneficial: 1
(a): 1
from: 3
date: 1
http://www.scalacheck.org): 1
mustache: 1
ParaNamer: 2
.scala: 1
managed: 1
Source: 8
remain: 1
CONDITIONS: 4
identification: 1
BSD: 7
display: 1
REPRODUCTION,: 1
: 1445
translation: 1
license/LICENSE-heapq.txt: 1
license.: 1
damages.: 1
format.: 1
designated: 1
Contribution.": 1
applicable: 3
(https://github.com/mustache/mustache/blob/master/LICENSE): 1
choose: 1
SerializableMapWrapper: 1
(MIT: 20
6.: 1
included: 4
retain,: 1
notice,: 1
owner: 4
details.: 2
Contributions): 1
(http://datatables.net/license): 1
its: 3
(50%): 1
writing: 1
document.: 1
such: 17
Contribution: 3
components: 2
distribute,: 2
page": 1
"Your"): 1
JUL: 1
additions: 1
non-exclusive,: 2
hereby: 2
software: 2
risks: 1
bridge: 1
IS": 2
lists,: 1
licence): 3
fee: 1
out: 1
required: 4
dagre-d3: 1
unless: 1
below).: 1
ownership: 2
========================================================================: 10
import,: 1
MinLog: 1
(org.slf4j:slf4j-log4j12:1.7.5: 1
terminate: 1
if: 4
prominent: 1
revisions,: 1
Apache: 6
all: 3
"License");: 1
written: 1
Warranty: 1
irrevocable: 2
inclusion: 2
(http://code.google.com/p/cookies/wiki/License): 1
Definitions.: 1
Derivative: 17
incurred: 1
terms.: 1
sell,: 2
Actors: 1
License): 29
Work,: 4
representatives,: 1
special,: 1
is: 11
Legal: 3
least: 1
same: 1
file,: 1
text: 6
editorial: 1
(http://www.jqueryscript.net/other/jQuery-Plugin-For-Pretty-JSON-Formatting-jsonFormatter.html): 1
redistributing: 2
"License": 1
link: 3
notice: 2
shall: 15
using: 1
and/or: 1
separate: 2
name): 1
form.: 1
annotations,: 1
subject: 1
negligent: 1
defend,: 1
files: 2
Work.: 1
(https://github.com/cpettitt/graphlib-dot): 1
NOTICE: 5
owner.: 1
infringed: 1
modifications: 3
Clause): 7
electronic,: 1
brackets!): 1
section): 1
(https://github.com/mbostock/d3/blob/master/LICENSE): 1
code: 2
acts): 1
scalacheck: 1
product: 1
warranty,: 1
liable: 1
(com.google.protobuf:protobuf-java:2.5.0: 1
Disclaimer: 1
represent,: 1
Subcomponents:: 1
Spark: 2
(https://github.com/bryanbraun/anchorjs): 1
(an: 1
Works": 1
"Licensor": 1
"Derivative: 1
library: 1
A: 1
incidental,: 1
Java: 3
Works: 12
pertain: 2
also: 3
tort: 1
conversions: 1
liability: 2
whether: 4
Submission: 1
TITLE,: 1
thereof.: 1
2.0: 1
royalty-free,: 2
entities: 1
interfaces: 1
or,: 1
"Not: 1
http://paranamer.codehaus.org/paranamer): 2
contents: 1
source: 3
http://pythonhosted.org/Pyro4/): 1
commercial: 1
Works,: 2
defined: 1
https://github.com/EsotericSoftware/minlog): 1
controlled: 1
(pyspark/heapq3.py):: 1
Warranty.: 1
implemented: 1
reason: 1
improving: 1
form,: 4
SnapTree:: 1
theory,: 1
(c): 1
applies: 1
(BSD-like): 5
perpetual,: 2
owner]: 1
JUnit-Interface: 1
jquery: 1
code,: 2
specific: 1
2004: 1
Object: 4
In: 1
SparkHelper.scala: 1
-: 33
(BSD): 3
those: 3
easier: 1
work,: 2
http://wwww.antlr.org/): 1
within: 8
worldwide,: 2
inability: 1
you: 2
cannot: 1
negligence),: 1
a: 21
determining: 1
writing,: 3
(com.esotericsoftware:minlog:1.3.0: 1
to: 42
https://github.com/jpmml/jpmml-model): 1
third-party: 2
core: 1
boto: 1
complies: 1
governing: 1
where: 1
liability.: 1
License,: 6
(com.esotericsoftware:kryo:3.0.3: 1
copyright: 11
compliance: 1
subsequently: 1
additional: 4
Contributor: 8
For: 6
NON-INFRINGEMENT,: 1
offer: 1
event: 1
"Contributor": 1
Grant: 2
license/LICENSE-jbcrypt.txt: 1
work.: 1
include: 3
content: 1
nothing: 1
add: 2
through: 1
perform,: 1
files;: 1
result: 1
goodwill,: 1
herein: 1
over: 1
http://xmlenc.sourceforge.net): 1
http://py4j.sourceforge.net/): 1
To: 1
any: 28
contract,: 1
ANY: 2
contract: 1
version: 1
4.: 1
these: 1
sbt: 1
MIT: 3
[name: 1
documentation,: 2
(org.spark-project.protobuf:protobuf-java:2.4.1-shaded: 1
control,: 1
origin: 1
no-charge,: 2
indicated: 1
recommend: 1
purposes: 4
wherever: 1
necessarily: 1
(https://github.com/cpettitt/dagre-d3): 1
separable: 1
contained: 1
FOR: 2
thereof,: 2
(antlr:antlr:2.7.7: 1
form: 8
Patent: 1
(org.antlr:stringtemplate:3.2.1: 1
8.: 1
constitutes: 1
(org.antlr:ST4:4.0.4: 1
types.: 1
alongside: 1
(org.antlr:antlr4:4.5.2-1: 1
implied.: 1
archives.: 1
warranty: 1
KIND,: 2
Fortran: 1
even: 1
(https://jquery.org/license/): 1
outstanding: 1
Copyright: 2
(org.scala-lang:scalap:2.11.8: 1
asserted: 1
We: 1
4.5.2-1: 1
responsible: 1
attach: 1
(org.scala-lang:scala-library:2.11.8: 1
support,: 1
has: 2
may: 9
New: 1
=======================================================================: 1
sublicense,: 1
granted: 2
blockUI: 1
implied,: 1
or: 62
(https://github.com/stuartlangridge/sorttable): 1
JCL: 1
limitation,: 1
licensable: 1
Licensor,: 1
(b): 1
law: 3
of: 65
does: 1
transformation: 1
(org.jpmml:pmml-model:1.2.7: 1
information.: 1
shares,: 1
modified: 1
supersede: 1
Licensed: 1
places:: 1
means: 2
identifying: 1
original: 2
machinist: 1
RowsGroup: 1
against,: 1
power,: 1
"Source": 1
each: 6
indirect,: 2
Liability.: 2
following: 6
"You": 1
damages,: 1
from): 1
(https://github.com/boto/boto/blob/develop/LICENSE): 1
tracking: 1
http://www.mockito.org): 1
obtain: 1
alleging: 1
(com.thoughtworks.paranamer:paranamer:2.3: 1
source,: 1
(iii): 1
syntax: 1
terms: 8
compiled: 1
example: 1
incorporated: 2
act: 1
issue: 1
provides: 2
limited: 4
license): 4
http://spire-math.org): 2
PURPOSE.: 1
"Contribution": 1
entity,: 1
no: 2
works: 1
media: 1
ARPACK: 1
mean: 10
individual: 3
4.0.4: 1
computer: 1
Scala: 5
Zstd: 1
notices: 9
agreed: 3
Licensor: 8
advised: 1
authorship,: 2
SLF4J: 4
Module: 1
subcomponents: 2
(the: 1
http://code.google.com/p/protobuf): 2
distribute: 3
modify: 2
You: 23
indemnity,: 1
grants: 2
(org.scala-lang:scala-reflect:2.11.8: 1
brackets: 1
modifying: 1
meet: 1
for,: 1
reproducing: 1
service: 1
boilerplate: 1
trademark,: 1
infringement,: 1
modernizr: 1
http://www.antlr.org/): 1
license/LICENSE-SnapTree.txt: 1
warranties: 1
Buffer: 2
distributed: 3
other: 7
submitted: 2
publicly: 2
sbt-launch-lib.bash: 1
OF: 3
display,: 1
derived: 1
damages: 3
use,: 4
name: 1
definition,: 2
that: 22
consistent: 1
electronic: 1
customary: 1
thereof: 1
claims: 2
https://github.com/fommil/netlib-java/core): 1
description: 1
construed: 1
trade: 1
addendum: 1
regarding: 1
END: 1
excluding: 3
(d): 1
License;: 1
direct: 2
modifications,: 3
under: 11
responsibility,: 1
https://github.com/EsotericSoftware/kryo): 1
The: 7
legal: 1
informational: 1
intentionally: 2
have: 2
received: 1
institute: 1
Appendix: 1
express: 2
(except: 1
loss: 1
common: 1
This: 1
BSD-style: 3
stating: 1
resulting: 1
(i): 1
conditions.: 1
marked: 1
License.: 12
whom: 1
along: 1
filed.: 1
Sections: 1
(https://github.com/Modernizr/Modernizr/blob/master/LICENSE): 1
losses),: 1
from,: 1
names,: 1
OR: 2
DISTRIBUTION: 1
the: 102
verbal,: 1
includes: 1
offer,: 1
obligations: 1
licenses: 3
assume: 1
not: 11
either: 2
datatables: 1
stoppage,: 1
submitted.: 1
provided: 7
otherwise,: 3
(net.sf.py4j:py4j:0.10.7: 1
as: 15
jsonFormatter: 1
purpose: 2
consequential: 1
generated: 2
licenses/LICENSE-[project].txt.: 2
merely: 1
AND: 3
rights: 1
(http://jquery.malsup.com/block/): 1
http://www.apache.org/licenses/: 1
(org.scala-lang:scala-actors:2.11.8: 1
deliberate: 1
Version: 2
Main.Scala,: 1
entity.: 2
Scalap: 1
(com.thoughtworks.paranamer:paranamer:2.6: 1
Additional: 1
conspicuously: 1
charge: 1
Parser: 1
heapq: 1
permission: 1
on: 11
(Don't: 1
against: 1
(org.slf4j:jcl-over-slf4j:1.7.5: 1
Trademarks.: 1
9: 1
union: 1
(and: 1
1: 1
including,: 1
BASIS,: 2
Entity: 3
(http://www.scala-lang.org/download/#License): 1
use: 6
enclosed: 2
[yyyy]: 1
1.1.1: 1
contains: 1
jbcrypt:: 1
Entity": 1
cookies: 1
xmlenc: 1
preferred: 1
(jline:jline:0.9.94: 1
http://javolution.org): 1
repl/src/main/scala: 1
available: 1
http://www.apache.org/licenses/LICENSE-2.0: 1
conditions: 8
LOG4J-12: 1
more: 1
(org.slf4j:slf4j-api:1.7.5: 1
solely: 1
graphlib-dot: 1
possibility: 1
direction: 1
making: 1
must: 4
fifty: 1
sent: 1
netlib: 1
(org.scalacheck:scalacheck_2.11:1.10.0: 1
APPENDIX:: 1
(org.spire-math:spire-macros_2.11:0.7.1: 1
elaborations,: 1
changed: 1
prepare: 1
describing: 1
only: 4
contributory: 1
normally: 1
scopt: 1
exercising: 1
WITHOUT: 2
documentation: 1
which: 2
patent,: 1
Javolution: 1
3.: 1
explicitly: 1
should: 1
Limitation: 1
(org.spire-math:spire_2.11:0.7.1: 1
Contribution(s): 3
character: 1
"NOTICE": 1
of,: 3
your: 4
(net.sourceforge.f2j:arpack_combined_all:0.1: 1
failure: 1
recipients: 1
communication: 3
then: 2
(including: 3
Redistribution.: 1
attribution: 4
(all: 1
by: 20
If: 2
an: 6
own: 4
submit: 1
2.0,: 1
(BSD-style): 3
systems: 1
patent: 5
grossly: 1
(New: 4
above,: 1
systems,: 1
distribution: 3
(The: 4
7.: 1
mailing: 1
(org.mockito:mockito-core:1.9.5: 1
Protocol: 2
with: 12
Notwithstanding: 1
January: 1
2: 1
cross-claim: 1
provide: 1
(such: 1
lawsuit): 1
arising: 1
based: 1
ANTLR: 3
Core: 2
medium,: 1
authorship.: 1
files.: 1
ExecutorClassLoader.scala),: 1
copies: 1
their: 2
statement: 1
(javolution:javolution:5.5.1: 1
CloudPickle: 1
work: 5
state: 1
by,: 3
Mockito: 1
attached: 1
appear.: 1
(com.github.scopt:scopt_2.11:3.2.0: 1
Generator: 1
Your: 9
Py4J: 1
(http://datatables.net/license/mit): 1
spire-macros: 1
hold: 1
and: 46
USE,: 1
comment: 1
DPark: 1
replaced: 1
mechanical: 1
executed: 1
2018-11-05 04:19:49 INFO  AbstractConnector:318 - Stopped Spark@51bba83f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-05 04:19:49 INFO  SparkUI:54 - Stopped Spark web UI at http://ip-10-1-1-100.ec2.internal:4040
2018-11-05 04:19:49 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2018-11-05 04:19:49 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2018-11-05 04:19:49 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-11-05 04:19:49 INFO  MemoryStore:54 - MemoryStore cleared
2018-11-05 04:19:49 INFO  BlockManager:54 - BlockManager stopped
2018-11-05 04:19:49 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-11-05 04:19:49 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-11-05 04:19:49 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-11-05 04:19:49 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-11-05 04:19:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-e411c35d-54a4-498d-955e-0019a9e2e1df
2018-11-05 04:19:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-f679099d-b286-4dc3-b0c8-e3680a50a31c
